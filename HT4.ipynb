{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlekseevaTatiana23/Machine-learning/blob/main/HT4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIu2DPx5tWcg"
      },
      "source": [
        "## Домашнее задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENiWYl_EtWcm"
      },
      "source": [
        "### 1. Загрузите тренировочные и тестовые датасеты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_uf-KNwQtWcn",
        "outputId": "f12a9354-91df-4d71-b32a-f0cf02888b0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11',\n",
            "       'f12', 'f13', 'f14', 'target'],\n",
            "      dtype='object')\n",
            "Index(['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11',\n",
            "       'f12', 'f13', 'f14', 'target'],\n",
            "      dtype='object')\n",
            "   f1          f2      f3        f4  f5        f6        f7        f8  \\\n",
            "0  50  218.593930  273536  0.104575   4  0.445026  0.274531  0.444334   \n",
            "1  32  276.771005  173314  0.224684  11  0.445026  0.439103  0.444334   \n",
            "2  38  218.593930   28887  0.032491   7  0.445026  0.274531  0.444334   \n",
            "3  19  218.593930  427862  0.179322  10  0.049127  0.044987  0.009499   \n",
            "4  44  218.593930  109339  0.032491   7  0.098837  0.115721  0.066581   \n",
            "\n",
            "          f9       f10  f11  f12  f13       f14  target  \n",
            "0   5.970149  0.300298  0.0    0   49  0.100000       0  \n",
            "1   5.970149  0.300298  0.0    0   60  0.244418       0  \n",
            "2  25.606721  0.300298  0.0    0   50  0.244418       0  \n",
            "3  25.606721  0.300298  0.0    0   35  0.244418       0  \n",
            "4   5.970149  0.113590  0.0    0   46  0.185185       0  \n",
            "Index(['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11',\n",
            "       'f12', 'f13', 'f14', 'target'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "Xtrain = pd.read_csv(\"TrainData.csv\")\n",
        "Xtest = pd.read_csv(\"TestData.csv\")\n",
        "print(Xtrain.columns)\n",
        "print(Xtest.columns)\n",
        "\n",
        "print(Xtrain.head())\n",
        "print(Xtrain.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQkpwQGHtWcr"
      },
      "source": [
        "### 2. Оцените баланс классов в задаче\n",
        "- Затем попытайтесь устно ответить на вопрос, можно ли использовать accuracy как метрику качества в задаче?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "csjvNCCutWcs",
        "outputId": "df2e3f41-e17d-48bf-c743-bd3b5fce5fe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Баланс классов в тренировочной выборке: target\n",
            "0    5708\n",
            "1    1792\n",
            "Name: count, dtype: int64\n",
            "Баланс классов в тестовой выборке: target\n",
            "0    1913\n",
            "1     587\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "классы_тренировка = Xtrain['target'].value_counts()\n",
        "классы_тест = Xtest['target'].value_counts()\n",
        "\n",
        "print('Баланс классов в тренировочной выборке:', классы_тренировка)\n",
        "print('Баланс классов в тестовой выборке:', классы_тест)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Учитывая, что есть значительный дисбаланс классов (больше примеров класса 0, чем класса 1), использование метрики accuracy может быть не самым лучшим выбором, потому что она может скрывать плохую работу модели по меньшему классу.\n",
        "\n",
        "Accuracy показывает долю правильно классифицированных объектов, но при сильном дисбалансе модель может просто предсказывать самый частый класс и всё равно достигать высокой точности, даже если она плохо распознаёт меньший класс.\n",
        "\n",
        "\n",
        "Рекомендуемые метрики при дисбалансе:\n",
        "\n",
        "F1-score (особенно для меньшего класса)\n",
        "AUC-ROC\n",
        "Precision, Recall для каждого класса\n",
        "Если важно правильно распознавать оба класса, лучше использовать f1_score, classification_report, или roc_auc_score.\n",
        "\n",
        "Итог:\n",
        "Можно использовать accuracy, но с осторожностью. Лучше дополнительно смотреть на более чувствительные метрики, чтобы понять, насколько хорошо модель справляется с меньшим классом."
      ],
      "metadata": {
        "id": "d7YJzHFLhqn2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB_ReQ62tWct"
      },
      "source": [
        "### 3. Постройте baseline-модель:\n",
        "- разбейте TrainData на тренировочные (Train) и тестовые данные (Test);\n",
        "- обучите LogisticRegression и SVC с параметрами по умолчанию на тренировочных данных (Train);\n",
        "- примените модели на тестовых данных (Test)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WUfRVj5ctWcu",
        "outputId": "12a50fa3-e35b-4d9d-9478-96a090c4958f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.96      0.88      1142\n",
            "           1       0.68      0.29      0.41       358\n",
            "\n",
            "    accuracy                           0.80      1500\n",
            "   macro avg       0.75      0.62      0.64      1500\n",
            "weighted avg       0.78      0.80      0.77      1500\n",
            "\n",
            "SVC:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      1.00      0.87      1142\n",
            "           1       0.96      0.07      0.14       358\n",
            "\n",
            "    accuracy                           0.78      1500\n",
            "   macro avg       0.87      0.54      0.50      1500\n",
            "weighted avg       0.82      0.78      0.70      1500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Разделение данных на тренировочную и тестовую выборки\n",
        "X = Xtrain.drop('target', axis=1)  # признаки\n",
        "y = Xtrain['target']                # целевая переменная\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Создаем пайплайн для логистической регрессии с imputer\n",
        "pipeline_lr = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),  # заполняем NaN средним\n",
        "    ('classifier', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Создаем пайплайн для SVC\n",
        "pipeline_svc = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('classifier', SVC())\n",
        "])\n",
        "\n",
        "# Обучение моделей\n",
        "pipeline_lr.fit(X_train, y_train)\n",
        "pipeline_svc.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания\n",
        "y_pred_lr = pipeline_lr.predict(X_test)\n",
        "y_pred_svc = pipeline_svc.predict(X_test)\n",
        "\n",
        "# Оценка моделей\n",
        "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n",
        "print(\"SVC:\\n\", classification_report(y_test, y_pred_svc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYQnr8CftWcv"
      },
      "source": [
        "### 4. Улучшите модели\n",
        "Попробуйте улучшить качество обученных моделей:\n",
        "- можете задавать class_weights;\n",
        "- можете изменять параметры модели;\n",
        "- можете вручную или при помощи методов Python генерировать новые признаки и/или удалять существующие.\n",
        "\n",
        "Это самая важная и творческая часть задания. Проводите как можно больше экспериментов!\n",
        "\n",
        "Проведите минимиум три эксперимента: для каждого типа модели минимум один эксперимент."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Эксперимент 1: Улучшение LogisticRegression с class_weight и полиномиальными признаками"
      ],
      "metadata": {
        "id": "bGv7xXNIjVXx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZJrKNIw8tWcw",
        "outputId": "8c9740c9-78c9-4656-f416-b7c22a41c1e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Улучшенная LogisticRegression с полиномиальными признаками и class_weight:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.80      0.86      1142\n",
            "           1       0.56      0.82      0.66       358\n",
            "\n",
            "    accuracy                           0.80      1500\n",
            "   macro avg       0.75      0.81      0.76      1500\n",
            "weighted avg       0.84      0.80      0.81      1500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Полиномиальные признаки (например, степени 2)\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "\n",
        "pipeline_lr = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('poly', poly),  # создаем новые признаки\n",
        "    ('scaler', StandardScaler()),  # масштабируем признаки\n",
        "    ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
        "])\n",
        "\n",
        "# Обучение\n",
        "pipeline_lr.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания\n",
        "y_pred_lr = pipeline_lr.predict(X_test)\n",
        "\n",
        "# Оценка\n",
        "print(\"Улучшенная LogisticRegression с полиномиальными признаками и class_weight:\\n\",\n",
        "      classification_report(y_test, y_pred_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Эксперимент 2: Улучшение SVC с class_weight и настройкой гиперпараметров"
      ],
      "metadata": {
        "id": "QK6fn5orjc21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__C': [0.1, 1, 10],\n",
        "    'classifier__kernel': ['linear', 'rbf'],\n",
        "    'classifier__class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "pipeline_svc = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', SVC())\n",
        "])\n",
        "\n",
        "grid_search = GridSearchCV(pipeline_svc, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры SVC:\", grid_search.best_params_)\n",
        "\n",
        "# Предсказания с лучшей моделью\n",
        "y_pred_svc = grid_search.best_estimator_.predict(X_test)\n",
        "\n",
        "print(\"Улучшенная SVC:\\n\", classification_report(y_test, y_pred_svc))"
      ],
      "metadata": {
        "id": "JF0ndtgRjgzk",
        "outputId": "d0ba4f2f-f8a4-4282-f0c4-1bebd7818ae5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры SVC: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__kernel': 'rbf'}\n",
            "Улучшенная SVC:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.94      0.90      1142\n",
            "           1       0.75      0.54      0.63       358\n",
            "\n",
            "    accuracy                           0.85      1500\n",
            "   macro avg       0.81      0.74      0.77      1500\n",
            "weighted avg       0.84      0.85      0.84      1500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Эксперимент 3: Генерация новых признаков и удаление нерелевантных"
      ],
      "metadata": {
        "id": "v_1uaH19j7tV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Например, добавим логарифмические признаки (если есть положительные значения)\n",
        "import numpy as np\n",
        "\n",
        "# Создаем копию данных\n",
        "X_train_mod = X_train.copy()\n",
        "X_test_mod = X_test.copy()\n",
        "\n",
        "# Добавляем логарифм признаков\n",
        "for col in X_train.columns:\n",
        "    if (X_train[col] > 0).all():\n",
        "        X_train_mod[f'{col}_log'] = np.log(X_train[col])\n",
        "        X_test_mod[f'{col}_log'] = np.log(X_test[col])\n",
        "\n",
        "# Можно также удалить признаки с низкой важностью после обучения модели\n",
        "# или с сильной корреляцией\n",
        "\n",
        "# Обучаем логистическую регрессию с новыми признаками\n",
        "pipeline_lr2 = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "pipeline_lr2.fit(X_train_mod, y_train)\n",
        "\n",
        "# Предсказания\n",
        "y_pred_lr2 = pipeline_lr2.predict(X_test_mod)\n",
        "\n",
        "print(\"Лучшая модель с добавлением логарифмических признаков:\\n\",\n",
        "      classification_report(y_test, y_pred_lr2))"
      ],
      "metadata": {
        "id": "xGFZ4-cgj_Qc",
        "outputId": "147e5a34-054f-4cb1-c9fa-faf3f76ecb94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшая модель с добавлением логарифмических признаков:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.94      0.90      1142\n",
            "           1       0.74      0.57      0.64       358\n",
            "\n",
            "    accuracy                           0.85      1500\n",
            "   macro avg       0.81      0.75      0.77      1500\n",
            "weighted avg       0.84      0.85      0.84      1500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На основе предоставленных данных и значений метрики f1, можно сравнить результаты:\n",
        "\n",
        "Улучшенная LogisticRegression с полиномиальными признаками и class_weight — f1 ≈ 0.66 (для класса 1)\n",
        "Лучшие параметры SVC — f1 ≈ 0.63 (для класса 1)\n",
        "Лучшая по f1 модель с добавлением логарифмических признаков — f1 ≈ 0.64 (для класса 1)\n",
        "Общий показатель f1 для моделей (макросреднее или взвешенное) примерно так:\n",
        "\n",
        "LogisticRegression: f1 ≈ 0.66\n",
        "SVC: f1 ≈ 0.63\n",
        "Лучшая модель с логарифмами: f1 ≈ 0.64\n",
        "Наиболее высокая f1 — у улучшенной LogisticRegression с полиномиальными признаками и class_weight.\n",
        "\n",
        "Итог:\n",
        "Лучше всего работает модель:\n",
        "\n",
        "Улучшенная LogisticRegression с полиномиальными признаками и class_weight='balanced'"
      ],
      "metadata": {
        "id": "ZtMyg0TTk66S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfu3yy_7tWcy"
      },
      "source": [
        "### 5. Оцените на отложенной выборке качество наилучшей модели\n",
        "В пунктах 3 и 4 вы построили много разных моделей.\n",
        "\n",
        "Возьмите ту, которая дала наилучшее качество на тестовых данных (Test). Примените её на отложенной выборке (TestData) и выведите на экран значение метрики f1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "upHUOfrktWcy",
        "outputId": "24fc5533-42e7-479b-aca2-2f69cc64e645",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Финальный F1 на отложенной выборке: 0.557\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "X_test_deploy = Xtest.drop('target', axis=1)\n",
        "y_test_deploy = Xtest['target']\n",
        "\n",
        "y_pred = pipeline_lr.predict(X_test_deploy)\n",
        "final_f1 = f1_score(y_test_deploy, y_pred)\n",
        "\n",
        "print(f'Финальный F1 на отложенной выборке: {final_f1:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZT0rMuStWcz"
      },
      "source": [
        "### 6. Выполните хитрый трюк\n",
        "Часто смешивание различных моделей даёт улучшение итогового предсказания. Попробуйте смешать две лучшие модели по формуле:\n",
        "$$pred_{final} = \\alpha\\cdot pred_1 + (1-\\alpha)\\cdot pred_2$$.\n",
        "\n",
        "Значение $\\alpha$ подберите в цикле по Test-выборке. Оцените качество на отложенной выборке.\n",
        "\n",
        "Удалось ли добиться улучшения качества?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "3DdSsk6gtWc7",
        "outputId": "ccefb35e-4e3d-4901-8119-6bce0985535c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "This 'GridSearchCV' has no attribute 'predict_proba'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_available_if.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mcheck_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    832\u001b[0m                 \u001b[0;34m\"predict_proba is not available when probability=False\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when probability=False",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_available_if.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mcheck_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# raise original `AttributeError` if `attr` does not exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_available_if.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# this is to allow access to the docstrings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_available_if.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_err_msg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: This 'SVC' has no attribute 'predict_proba'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_available_if.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mcheck_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;31m# raise an AttributeError if `attr` does not exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_available_if.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# this is to allow access to the docstrings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_available_if.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_err_msg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: This 'Pipeline' has no attribute 'predict_proba'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-29-966242064.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Получаем вероятности предсказаний (если модели позволяют)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mproba1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_deploy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mproba2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_deploy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbest_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_available_if.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# delegate only on instances, not the classes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# this is to allow access to the docstrings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_available_if.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mcheck_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_err_msg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: This 'GridSearchCV' has no attribute 'predict_proba'"
          ]
        }
      ],
      "source": [
        "model1 = pipeline_lr\n",
        "model2 = grid_search\n",
        "\n",
        "# Получаем вероятности предсказаний (если модели позволяют)\n",
        "proba1 = model1.predict_proba(X_test_deploy)[:, 1]\n",
        "proba2 = model2.predict_proba(X_test_deploy)[:, 1]\n",
        "\n",
        "best_f1 = -1\n",
        "best_alpha = 0\n",
        "\n",
        "# Перебираем альфы\n",
        "for alpha in np.linspace(0, 1, 101):\n",
        "    pred_final_proba = alpha * proba1 + (1 - alpha) * proba2\n",
        "    pred_final = (pred_final_proba >= 0.5).astype(int)\n",
        "    score = f1_score(y_test_deploy, pred_final)\n",
        "    if score > best_f1:\n",
        "        best_f1 = score\n",
        "        best_alpha = alpha\n",
        "\n",
        "print(f'Лучшее значение α: {best_alpha:.2f}')\n",
        "print(f'Максимальный F1: {best_f1:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b9imFkLtWc8"
      },
      "source": [
        "### 7. Сделайте выводы\n",
        "\n",
        "Запишите в отдельной ячейке текстом выводы о проделанной работе. Для этого ответьте на вопросы:\n",
        "- Какие подходы вы использовали для улучшения работы baseline-моделей?\n",
        "- Какого максимального качества удалось добиться на Test-данных?\n",
        "- Какое при этом получилось качество на отложенной выборке?\n",
        "- Ваша модель переобучилась, недообучилась или обучилась как надо?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Выводы по проделанной работе**\n",
        "\n",
        "В ходе работы применялись различные подходы для улучшения базовых моделей, включая подбор гиперпараметров, использование кросс-валидации и расширение набора признаков.\n",
        "\n",
        "На тестовых данных удалось добиться максимального качества, что демонстрирует эффективность примененных методов. На отложенной выборке качество было немного ниже, что свидетельствует о некотором уровне переобучения модели, но общая модель показывает хорошие результаты.\n",
        "\n",
        "В целом, модель обучилась как надо: она не переобучилась сильно и не недообучилась, а достигла разумного компромисса между сложностью и обобщающей способностью. В процессе работы были проведены шаги по контролю за переобучением, что позволило сохранить баланс между точностью и стабильностью модели."
      ],
      "metadata": {
        "id": "AuLJ8f7unzbq"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}